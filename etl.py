import pandas as pd
import yaml
import re
import io
import os
from bs4 import BeautifulSoup

# =======================================================
# 0. å…¨åŸŸå¸¸æ•¸å®šç¾© (Global Constants)
# =======================================================
COL_TXN_DATE = 'Transaction_Date'
COL_POST_DATE = 'Posting_Date'
COL_MERCHANT = 'Merchant'
COL_LOCATION = 'Merchant_Location'
COL_CONSUMPTION_PLACE = 'Consumption_Place'     # ç‰å±±åœ‹å¤–äº¤æ˜“æ‹†è§£ç”¨
COL_CONV_DATE = 'Conversion_Date'
COL_CURRENCY = 'Currency_Type'
COL_AMOUNT = 'Amount'
COL_CURR_AMOUNT = 'Currency_Amount'
COL_PAY_AMOUNT = 'Payment_Amount'               # å°å¹£æ‡‰ç¹³é‡‘é¡
COL_PAY_CURR = 'Payment_Currency'
COL_CARD_NO = 'Card_No'
COL_CARD_TYPE = 'Card_Type'
COL_TXN_TYPE = 'Transaction_Type'
COL_MOBILE_PAY = 'Mobile_Payment'
COL_BANK_NAME = 'Bank_Name'
COL_RAW_COUNTRY_CURR = 'Raw_Country_Currency'   # åœ‹æ³°ç”¨

# =======================================================
# Part 1: Shared Utilities (å·¥å…·å‡½å¼)
# =======================================================
def load_config(config_path):
    with open(config_path, 'r', encoding='utf-8') as file:
        return yaml.safe_load(file)

def normalize_country_code(code):
    # ==========================================
    # Debug å€åŸŸï¼šé‡å°ç‰¹å®šé—œéµå­—é€²è¡Œè©³ç´°ç›£æ§ (å¯è¦–æƒ…æ³é—œé–‰)
    # ==========================================
    debug_mode = 'JPN' in str(code) 
    
    if debug_mode:
        print(f"   ğŸ•µï¸ [Trace] é€²å…¥å‡½å¼ Input: '{code}' (Type: {type(code)})")

    # 1. åŸºç¤é˜²å‘†
    if pd.isna(code) or code is None:
        if debug_mode: print("   ğŸ•µï¸ [Trace] -> åˆ¤å®šç‚º None/NaN -> Return 'TW'")
        return 'TW'
    
    s_code = str(code)
    stripped_code = s_code.strip()
    is_empty = (stripped_code == '')
    
    if debug_mode:
        print(f"   ğŸ•µï¸ [Trace] Strip Check: åŸå­—ä¸² '{s_code}' -> å»ç©ºç™½å¾Œ '{stripped_code}'")
        print(f"   ğŸ•µï¸ [Trace] Is Empty? {is_empty}")

    if is_empty:
        if debug_mode: print("   ğŸ•µï¸ [Trace] -> åˆ¤å®šç‚ºç©ºå­—ä¸² -> Return 'TW'")
        return 'TW'

    # 2. å‰ç½®æ¸…æ´— (æ ¸å¿ƒé‚è¼¯ï¼šå–é¦–å­—)
    # "JPN CHIYODA-KU" -> "JPN"
    clean_code = stripped_code.upper().split(' ')[0]
    
    if debug_mode:
        print(f"   ğŸ•µï¸ [Trace] Split Logic: '{stripped_code}' -> å–é¦–å­— -> '{clean_code}'")

    # 3. 3ç¢¼è½‰2ç¢¼å°ç…§è¡¨
    mapping_3to2 = {
        'TWN': 'TW', 'USA': 'US', 'JPN': 'JP', 'KOR': 'KR',
        'HKG': 'HK', 'SGP': 'SG', 'GBR': 'GB', 'CHN': 'CN',
        'IRL': 'IE', 'DEU': 'DE', 'FRA': 'FR', 'AUS': 'AU',
        'VNM': 'VN', 'THA': 'TH', 'MYS': 'MY', 'IDN': 'ID'
    }
    
    # 4. æŸ¥è¡¨èˆ‡å›å‚³
    result = clean_code
    if clean_code in mapping_3to2:
        result = mapping_3to2[clean_code]
    elif len(clean_code) == 2:
        result = clean_code
    
    if debug_mode:
        print(f"   ğŸ•µï¸ [Trace] Final Result: '{result}'\n")

    return result

def parse_date_with_year(date_str, base_year, bill_month):
    s = str(date_str).strip()
    if pd.isna(date_str) or s in ['(null)', 'nan', '']:
        return pd.NaT
    try:
        parts = re.split(r'[/-]', s)
        # æœˆ/æ—¥ (01/15) -> è£œå¹´ä»½ + è·¨å¹´é‚è¼¯
        if len(parts) == 2:
            month = int(parts[0])
            day = int(parts[1])
            final_year = base_year
            # é‚è¼¯ï¼šå¸³å–®æ˜¯1æœˆï¼Œä½†å‡ºç¾12æœˆæ¶ˆè²» -> è‚¯å®šæ˜¯å»å¹´
            if bill_month == 1 and month == 12: final_year -= 1
            # é‚è¼¯ï¼šå¸³å–®æ˜¯12æœˆï¼Œä½†å‡ºç¾1æœˆæ¶ˆè²» -> è‚¯å®šæ˜¯æ˜å¹´ (æ¥µå°‘è¦‹ä½†é˜²ç¦¦)
            if bill_month == 12 and month == 1: final_year += 1
            return pd.Timestamp(year=final_year, month=month, day=day)
        # å·²æœ‰å¹´ä»½ (2024/01/15)
        elif len(parts) == 3:
            return pd.to_datetime(s, errors='coerce')
        else:
            return pd.NaT
    except Exception:
        return pd.NaT

# =======================================================
# Part 2: Nodes (è™•ç†ç¯€é»)
# =======================================================

# [Node 1] æ™ºæ…§è®€å–å™¨ (Smart Ingest)
def smart_read_csv(filepath, encoding, header_keyword):
    content_buffer = ""
    found_header = False
    try:
        with open(filepath, 'r', encoding=encoding, errors='replace') as f:
            all_lines = f.readlines()
        
        # æƒæå‰ 50 è¡Œæ‰¾æ¨™é¡Œ (å‹•æ…‹éŒ¨é»)
        for i, line in enumerate(all_lines):
            if i > 50: break
            if header_keyword and header_keyword in line:
                content_buffer = "".join(all_lines[i:])
                found_header = True
                print(f"   ğŸ“ æ¨™é¡Œå®šä½æˆåŠŸï¼šç¬¬ {i+1} è¡Œ")
                break
        
        if found_header:
            return pd.read_csv(io.StringIO(content_buffer), on_bad_lines='skip')
        else:
            print("   âš ï¸ æœªåµæ¸¬åˆ°æ¨™é¡Œé—œéµå­—ï¼Œå˜—è©¦ç›´æ¥è®€å–...")
            return pd.read_csv(filepath, encoding=encoding, header=0, on_bad_lines='skip')
    except Exception as e:
        print(f"   âŒ Smart Read å¤±æ•—: {e}")
        return None

# [Node 3] å¡è™Ÿæå– (Feature Extraction - é€šç”¨ç‰ˆ)
def extract_card_info(df, bank_id, col_merchant, col_card_no, col_card_type):
    target_banks = ['esun_bank', 'hncb_bank']
    if bank_id not in target_banks or col_merchant not in df.columns:
        return df

    # é…ç½®èˆ‡é‚è¼¯åˆ†é›¢
    patterns = {
        'esun_bank': {
            'trigger': 'å¡è™Ÿï¼š',# ç‰å±±ç‰¹å¾µï¼šå¡è™Ÿï¼šXXXX-XXXX-XXXX-"NNNN"ï¼ˆ"ç‰å±±å¡åˆ¥"ï¼æ­£å¡ï¼‰
            'card_no': r'(\d{4})ï¼ˆ',
            'card_type': r'ï¼ˆ(.*?)ï¼?(?:æ­£å¡|é™„å¡)ï¼‰'
        },
        'hncb_bank': {
            'trigger': r'\*{12}', # è¯å—ç‰¹å¾µï¼š"è¯å—å¡åˆ¥"************"NNNN"
            'card_no': r'\*{12}(\d{4})',
            'card_type': r'^(.*?)\*{12}' # æ˜Ÿè™Ÿå‰é¢çš„å°±æ˜¯å¡åˆ¥
        }
    }
    config = patterns.get(bank_id)
    
    # åŸ·è¡Œ Tag -> Fill -> Extract
    mask_master = df[col_merchant].astype(str).str.contains(config['trigger'], na=False, regex=True)
    if mask_master.any():
        print(f"   ğŸ”§ [{bank_id}] åŸ·è¡Œå¡è™Ÿæå– (Group & Fill)...")
        df.loc[mask_master, 'raw_master_info'] = df.loc[mask_master, col_merchant]
        df['raw_master_info'] = df['raw_master_info'].ffill()
        
        df[col_card_no] = df['raw_master_info'].str.extract(config['card_no'])
        if config.get('card_type'):
            df[col_card_type] = df['raw_master_info'].str.extract(config['card_type'])
            
        df = df[~mask_master].copy() # åˆªé™¤ Master è¡Œ
        df = df.drop(columns=['raw_master_info'])
        
    return df

# [Node 4-1] ç‰å±±å°ˆå±¬è§£æ
def parse_esun_details(df, col_merchant, col_location, col_conv_date, base_year, bill_month):
    if col_merchant not in df.columns: return df
    print("   ğŸ”§ [ç‰å±±] åŸ·è¡Œåœ‹å¤–äº¤æ˜“è³‡æ–™æ‹†è§£ (æ¶ˆè²»åœ°èˆ‡æ—¥æœŸ)...")
    
    df[col_merchant] = df[col_merchant].astype(str).str.strip()
    
    # Regex æ›´æ–°: å¯¬å®¹æ¨¡å¼ï¼Œé©æ‡‰ 2 ç¢¼æˆ–å¤šç¢¼åœ°é»
    # çµæ§‹: (æ¶ˆè²»æ˜ç´°) (åˆ†éš”:2ç©ºç™½æˆ–Tab) (æ¶ˆè²»åœ°:åœ‹åˆ¥+åœ°é») (åˆ†éš”:è‡³å°‘1ç©ºç™½)+(æ—¥æœŸï¼šæŠ˜ç®—æ—¥MM/DD)?
    pat = r'^(.*?)(?:\s{2,}|\t)(.*?)(?:\s+(\d{2}/\d{2}))?$'
    
    ext = df[col_merchant].str.extract(pat)
    
    # [Debug] æ‰‹è¡“å°è¦–è§’ï¼šæª¢æŸ¥åˆ‡åˆ†çµæœ
    debug_mask = ext[1].notna()
    if debug_mask.any():
        print("\n   ğŸ” [Debug] ç‰å±±åœ‹å¤–äº¤æ˜“æ‹†è§£é è¦½ (å‰ 5 ç­†):")
        debug_view = pd.DataFrame({
            'åŸå§‹å­—ä¸²': df.loc[debug_mask, col_merchant],
            'G1_å•†åº—å': ext.loc[debug_mask, 0],
            'G2_æ¶ˆè²»åœ°': ext.loc[debug_mask, 1],
            'G3_æ—¥æœŸ':   ext.loc[debug_mask, 2]
        })
    #    print(debug_view.head().to_string())
        print("-" * 60)

    # å›å¡«è³‡æ–™
    # 1. ä¿®æ­£å•†åº—åç¨±
    has_name = ext[0].notna()
    df.loc[has_name, col_merchant] = ext[0].str.strip() 
    
    # 2. å¡«å…¥æ¶ˆè²»åœ° (Consumption Place)
    df.loc[ext[1].notna(), col_location] = ext[1].str.strip()
    
    # 3. å¡«å…¥æ›åŒ¯æ—¥æœŸ
    df.loc[ext[2].notna(), col_conv_date] = ext[2]
    
    return df

# [Node 4-2] åœ‹æ³°å°ˆå±¬è§£æ
def parse_cube_details(df, col_raw, col_location, col_currency):
    if col_raw in df.columns:
        print("   ğŸ”§ [åœ‹æ³°] åŸ·è¡Œ æ¶ˆè²»åœ‹å®¶(TW)/å¹£åˆ¥(TWD) æ‹†è§£...")
        split = df[col_raw].astype(str).str.split(' / ', n=1, expand=True)
        if split.shape[1] >= 1:
            df[col_location] = split[0].str.strip().apply(normalize_country_code)
        if split.shape[1] >= 2:
            df[col_currency] = split[1].str.strip()
        df = df.drop(columns=[col_raw])
    return df

# =======================================================
# Part 3: Main Pipeline (ä¸»æµç¨‹)
# =======================================================
def process_bank_file(filepath, bank_id, config):
    print(f"æ­£åœ¨è™•ç†ï¼š{bank_id} ({os.path.basename(filepath)})...") 
    bank_config = config.get(bank_id)
    if bank_config is None:
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° {bank_id} è¨­å®š")
        return None

    # 0. ç’°å¢ƒè®Šæ•¸è¨­å®š
    current_encoding = bank_config.get('encoding', 'utf-8')
    header_keyword = bank_config.get('header_keyword')
    file_type = bank_config.get('file_type', 'csv')

    # 1. Init: è§£ææª”åä»¥ç²å–å¹´ä»½ (æ ¸å¿ƒä¾è³´)
    base_year = 2024; bill_month = 1 
    filename = os.path.basename(filepath)
    match_western = re.search(r'(20\d{2})(\d{2})', filename)
    match_roc = re.search(r'(\d{2,3})å¹´(\d{1,2})æœˆ', filename)
    
    if match_roc:
        base_year = int(match_roc.group(1)) + 1911
        bill_month = int(match_roc.group(2))
    elif match_western:
        base_year = int(match_western.group(1))
        bill_month = int(match_western.group(2))

    df = None

    # =======================================================
    # Node 1: Ingest (è®€å–)
    # =======================================================
    # [Path A] è¯å— HTML (ç‰¹æ®Šè™•ç†)
    if bank_id == 'hncb_bank':
        try:
            with open(filepath, 'r', encoding=current_encoding, errors='replace') as f:
                soup = BeautifulSoup(f, 'lxml')
            header_node = soup.find(string=lambda t: t and header_keyword in t)
            if header_node and header_node.find_parent('table'):
                target_table = header_node.find_parent('table')
                dfs = pd.read_html(io.StringIO(str(target_table)), header=0)
                if dfs:
                    df = dfs[0]
                    # HTML æ¸…æ´—ï¼šå£“æ‰æ›è¡Œç¬¦è™Ÿ
                    df.columns = [" ".join(str(c).replace('\n', ' ').split()) for c in df.columns]
                    print("   âœ… HTML è¡¨æ ¼è§£ææˆåŠŸ")
        except Exception as e:
            print(f"   âŒ è¯å— HTML è™•ç†å¤±æ•—: {e}")
            return None

    # [Path B] é€šç”¨ CSV/Text (åŒ…å«ç‰å±±ã€åœ‹æ³°ã€ä¸­ä¿¡)
    elif file_type == 'csv' or bank_id == 'esun_bank':
        df = smart_read_csv(filepath, current_encoding, header_keyword)
    
    # [Path C] çœŸ Excel
    elif file_type == 'excel':
        try:
            df = pd.read_excel(filepath) 
        except Exception as e:
             print(f"âŒ Excel è®€å–å¤±æ•—: {e}")

    if df is None or df.empty: return None
    df.columns = df.columns.astype(str).str.strip()

    # =======================================================
    # Node 2: Mapping (æ¬„ä½æ˜ å°„)
    # =======================================================
    mapping = bank_config.get('columns_mapping', {})
    existing_cols = df.columns.tolist()
    available_cols = [c for c in mapping.keys() if c in existing_cols]
    if available_cols:
        df = df[available_cols]
        df = df.rename(columns=mapping)
    df[COL_BANK_NAME] = bank_id

    # åˆå§‹åŒ–å¿…è¦æ¬„ä½
    for col in [COL_LOCATION, COL_CURRENCY, COL_CONV_DATE, COL_CARD_NO, COL_CARD_TYPE, 
                COL_PAY_AMOUNT, COL_PAY_CURR, COL_CURR_AMOUNT]:
        if col not in df.columns: df[col] = None

    # =======================================================
    # Node 3: Extraction (ç‰¹å¾µæå–)
    # =======================================================
    df = extract_card_info(df, bank_id, COL_MERCHANT, COL_CARD_NO, COL_CARD_TYPE)

    # =======================================================
    # Node 4: Specific (éŠ€è¡Œå°ˆå±¬æ¸…æ´—)
    # =======================================================
    if bank_id == 'esun_bank':
        df = parse_esun_details(df, COL_MERCHANT, COL_CONSUMPTION_PLACE, COL_CONV_DATE, base_year, bill_month)
        
        # [Node 4 æ¬é‹å·¥] å°‡ Node 4-1 æŠ“åˆ°çš„æ¶ˆè²»åœ°è³‡è¨Šå¡«å…¥ location æ¬„ä½
        if COL_CONSUMPTION_PLACE in df.columns:
            raw_places = df.loc[df[COL_CONSUMPTION_PLACE].notna(), COL_CONSUMPTION_PLACE].unique()
            if len(raw_places) > 0:
                print(f"   ğŸ” [Debug Node 4-1 å¾Œ] æŠ“åˆ°çš„æ¶ˆè²»åœ° (consumption_place): {raw_places}")
        
        if COL_CONSUMPTION_PLACE in df.columns and COL_LOCATION in df.columns:
            print("   ğŸ”§ [ç‰å±±] å°‡æ¶ˆè²»åœ°è³‡è¨Šå¡«å…¥ location_country æ¬„ä½...")
            mask_has_place = df[COL_CONSUMPTION_PLACE].notna()
            df.loc[mask_has_place, COL_LOCATION] = df.loc[mask_has_place, COL_CONSUMPTION_PLACE]

    elif bank_id == 'cube_bank':
        df = parse_cube_details(df, COL_RAW_COUNTRY_CURR, COL_LOCATION, COL_CURRENCY)

    elif bank_id == 'ctbc_bank':
        if COL_LOCATION in df.columns:
            df[COL_LOCATION] = df[COL_LOCATION].fillna('TW')
        df[COL_CURRENCY] = df[COL_CURRENCY].fillna('TWD')
        
    elif bank_id == 'hncb_bank':
        if COL_LOCATION in df.columns:
            df[COL_LOCATION] = df[COL_LOCATION].fillna('TW')

    print(f"\n   ğŸ” [Debug] æª”ååµæ¸¬åˆ°çš„ Base Year: {base_year}, Month: {bill_month}")
    
    if COL_TXN_DATE in df.columns:
        print(f"   ğŸ” [Debug] åŸå§‹äº¤æ˜“æ—¥æœŸç¯„ä¾‹ (å‰5ç­†):")
        print(df[COL_TXN_DATE].head().tolist()) 
        first_date = df[COL_TXN_DATE].iloc[0] if not df.empty else "No Data"
        parsed_result = parse_date_with_year(first_date, base_year, bill_month)
        print(f"   ğŸ” [Debug] è©¦è½‰ç¬¬ä¸€ç­†: '{first_date}' -> {parsed_result}")
    else:
        print(f"   âŒ [Critical] å±…ç„¶æ²’æœ‰ {COL_TXN_DATE} æ¬„ä½ï¼Ÿå‰é¢ Mapping ä¸æ˜¯èªªæœ‰å—ï¼Ÿ")

    # =======================================================
    # Node 5: General (é€šç”¨æ¸…æ´—èˆ‡é˜²å‘†)
    # =======================================================
    
    # 1. å¡è™Ÿæ¸…ç†
    if COL_CARD_NO in df.columns:
        df[COL_CARD_NO] = df[COL_CARD_NO].astype(str).str.replace(r'\.0$', '', regex=True)
        df[COL_CARD_NO] = df[COL_CARD_NO].replace({'nan': None, 'NaN': None, '': None})

    # 2. æ—¥æœŸè§£æ
    for col in [COL_TXN_DATE, COL_POST_DATE, COL_CONV_DATE]:
        if col in df.columns:
            df[col] = df[col].apply(lambda x: parse_date_with_year(x, base_year, bill_month))
            if col == COL_TXN_DATE: df = df.dropna(subset=[col])

    # 3. é‡‘é¡æ¸…æ´—
    for col in [COL_AMOUNT, COL_PAY_AMOUNT, COL_CURR_AMOUNT]:
        if col in df.columns:
            s = df[col].astype(str).str.strip().str.replace(',', '')
            df[col] = pd.to_numeric(s, errors='coerce')

    # 4. ç¹³æ¬¾é‡‘é¡/å¹£åˆ¥è£œå®Œ
    if COL_PAY_AMOUNT in df.columns and COL_AMOUNT in df.columns:
        df[COL_PAY_AMOUNT] = df[COL_PAY_AMOUNT].fillna(df[COL_AMOUNT])
    if COL_PAY_CURR in df.columns:
        df[COL_PAY_CURR] = df[COL_PAY_CURR].fillna('TWD')

    # 5. åœ°é»èˆ‡å¹£åˆ¥æ¨™æº–åŒ–
    if COL_LOCATION in df.columns:
        # [Debug] Node 5 ç›£æ§
        raw_locs = df.loc[df[COL_LOCATION].notna(), COL_LOCATION].unique()
        if len(raw_locs) > 0:
            print(f"   ğŸ” [Debug Node 5] æ­£è¦åŒ–å‰ Location (Unique): {raw_locs}")
            
        df[COL_LOCATION] = df[COL_LOCATION].apply(normalize_country_code)

        # [Debug] Node 5 ç›£æ§
        norm_locs = df.loc[df[COL_LOCATION].notna(), COL_LOCATION].unique()
        if len(norm_locs) > 0:
            print(f"   ğŸ” [Debug Node 5] æ­£è¦åŒ–å¾Œ Location (Unique): {norm_locs}")

    # 6. åœ‹å…§äº¤æ˜“æ¸…ç†
    mask_domestic = df[COL_LOCATION] == 'TW'
    df.loc[mask_domestic, COL_CURRENCY] = None    # åœ‹å…§ä¸éœ€æ¨™ç¤ºå¹£åˆ¥
    df.loc[mask_domestic, COL_CURR_AMOUNT] = None # åœ‹å…§ä¸éœ€æ¨™ç¤ºå¤–å¹£é‡‘é¡

    # 7. åœ‹å¤–äº¤æ˜“é è¨­ TWD
    mask_foreign_empty = (df[COL_LOCATION] != 'TW') & df[COL_CURRENCY].isna()
    if mask_foreign_empty.any():
        df.loc[mask_foreign_empty, COL_CURRENCY] = 'TWD'

    return df

# =======================================================
# Part 4: Main Execution (ä¸»åŸ·è¡Œå€)
# =======================================================
if __name__ == "__main__":
    config_path = 'configs/banks_config.yaml'
    if not os.path.exists(config_path):
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è¨­å®šæª” {config_path}")
        exit()
        
    config = load_config(config_path)
    
    bank_keyword_map = {
        'ç‰å±±': 'esun_bank',
        'åœ‹æ³°': 'cube_bank', 'åœ‹æ³°ä¸–è¯': 'cube_bank',
        'ä¸­ä¿¡': 'ctbc_bank', 'ä¸­åœ‹ä¿¡è¨—': 'ctbc_bank',
        'è¯å—': 'hncb_bank',
        'æ°¸è±': 'sinopac_bank', 'DAWAY': 'sinopac_bank'
    }
    data_folder = 'data'
    all_data = []

    print(f"ğŸ“‚ æƒæç›®éŒ„: {data_folder}")
    if os.path.exists(data_folder):
        file_list = os.listdir(data_folder)
        for filename in file_list:
            if filename.startswith('.') or not re.search(r'\.(csv|xlsx|xls|html)$', filename, re.I):
                continue
            
            detected_bank_id = None
            for keyword, bank_id in bank_keyword_map.items():
                if keyword in filename:
                    detected_bank_id = bank_id
                    break
            
            if detected_bank_id:
                full_path = os.path.join(data_folder, filename)
                cleaned_df = process_bank_file(full_path, detected_bank_id, config)
                if cleaned_df is not None:
                    all_data.append(cleaned_df)
            else:
                 print(f"âš ï¸  ç•¥é (æœªåŒ¹é…éŠ€è¡Œ): {filename}")

    if all_data:
        final_df = pd.concat(all_data, ignore_index=True)
        
        desired_cols = [
            COL_TXN_DATE, COL_POST_DATE, COL_MERCHANT, COL_LOCATION, COL_CONSUMPTION_PLACE,
            COL_CURRENCY, COL_CONV_DATE, COL_AMOUNT, COL_CURR_AMOUNT, 
            COL_PAY_AMOUNT, COL_PAY_CURR, 
            COL_TXN_TYPE, COL_MOBILE_PAY, COL_CARD_TYPE, COL_CARD_NO, COL_BANK_NAME
        ]

        final_cols = [c for c in desired_cols if c in final_df.columns]

        print("\n=== çµæœé è¦½ ===")
        print(final_df[final_cols].head())
        
        output_path = "data/result_all_banks.csv"
        final_df[final_cols].to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"\nâœ… è™•ç†å®Œæˆï¼Œçµæœå·²è¼¸å‡ºè‡³: {output_path}")
    else:
        print("ç„¡è³‡æ–™ç”¢å‡º")