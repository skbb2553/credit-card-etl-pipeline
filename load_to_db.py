import pandas as pd
import sqlite3
import hashlib
import os
import numpy as np

# ==========================================
# 0. é…ç½®èˆ‡è·¯å¾‘
# ==========================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, 'data')

INPUT_CSV = os.path.join(DATA_DIR, 'refined_all_banks.csv')
DB_NAME = 'Bills.db' 
DB_PATH = os.path.join(DATA_DIR, DB_NAME)
TABLE_NAME = 'all_transactions'

# ==========================================
# 1. è¼”åŠ©å‡½å¼ï¼šç”Ÿæˆå”¯ä¸€ ID
# ==========================================
def generate_transaction_id(row):
    """
    å»ºç«‹å”¯ä¸€çš„äº¤æ˜“ ID (Hash)
    çµ„åˆï¼šæ—¥æœŸ + å•†å®¶ + é‡‘é¡ + å¡è™Ÿ + äº¤æ˜“é¡å‹
    """
    # è½‰å­—ä¸²ä¸¦è™•ç† Noneï¼Œç¢ºä¿ Hash ç©©å®š
    def safe_str(val):
        return str(val).strip() if pd.notna(val) else ""

    unique_str = (
        safe_str(row.get('Transaction_Date')) +
        safe_str(row.get('Merchant')) +
        safe_str(row.get('Card_No')) +
        safe_str(row.get('Payment_Amount')) + 
        safe_str(row.get('Transaction_Type'))
    )
    # å›å‚³ MD5 Hash
    return hashlib.md5(unique_str.encode('utf-8')).hexdigest()

# ==========================================
# 2. æ ¸å¿ƒé‚è¼¯
# ==========================================
def load_csv_and_save_to_db():
    if not os.path.exists(INPUT_CSV):
        print(f"âŒ éŒ¯èª¤: æ‰¾ä¸åˆ° CSV æª”æ¡ˆ: {INPUT_CSV}")
        return

    print(f"ğŸ“‚ è®€å– CSV: {INPUT_CSV}")
    
    # å®šç¾©è®€å–å‹æ…‹
    dtype_mapping = {
        'Currency_Amount': float,
        'Payment_Amount': float,
        'Card_No': str,
        'Mobile_Payment': str,
        'Merchant': str
    }
    
    try:
        df = pd.read_csv(INPUT_CSV, dtype=dtype_mapping)
        
        # 1. ç”Ÿæˆ Primary Key (Transaction_ID)
        print("ğŸ”¨ æ­£åœ¨ç”Ÿæˆäº¤æ˜“é›œæ¹Š ID (Transaction Hash)...")
        df['transaction_id'] = df.apply(generate_transaction_id, axis=1)

        # 2. æ¬„ä½æ›´å (Mapping to Snake Case)
        # è®“è³‡æ–™åº«æ¬„ä½è®Šæˆå°å¯«åº•ç·šé¢¨æ ¼ï¼Œæ¯”è¼ƒå¥½å¯« SQL
	# æ¬„ä½é †åºï¼š
        # 1.æ—¥æœŸçµ„ï¼š Transaction_Date, Posting_Date, Conversion_Date
        # 2.å¡ç‰‡çµ„ï¼š Bank_Name, Card_Type, Card_No
        # 3.å•†å®¶çµ„ï¼š Merchant, Merchant_Location, Consumption_Place
        # 4.äº¤æ˜“çµ„ï¼š Transaction_Type, Mobile_Payment
        # 5.é‡‘é¡çµ„ï¼š Currency_Amount, Payment_Amount, Currency_Type, Payment_Currency
    
        rename_map = {
            'Transaction_Date': 'transaction_date',
            'Posting_Date': 'posting_date',
            'Conversion_Date': 'conversion_date',
            'Bank_Name': 'bank_name',
            'Card_Type': 'card_name',     # å°æ‡‰æ‚¨çš„ card_name
            'Card_No': 'card_no',
            'Merchant': 'merchant_name',  # å°æ‡‰æ‚¨çš„ merchant_name
            'Merchant_Location': 'merchant_location',
            'Consumption_Place': 'consumption_place',
            'Transaction_Type': 'transaction_type',
            'Mobile_Payment': 'mobile_payment',
            'Currency_Amount': 'currency_amount',
            'Payment_Amount': 'payment_amount',
            'Currency_Type': 'currency_type',
            'Payment_Currency': 'payment_currency'
        }
        
        # åªé¸å–æœ‰å®šç¾©çš„æ¬„ä½ï¼Œé¿å…å¯«å…¥ä¸å¿…è¦çš„é›œè¨Š
        available_cols = [c for c in rename_map.keys() if c in df.columns]
        df_db = df[available_cols].rename(columns=rename_map)
        
        # æŠŠ transaction_id åŠ å›å» (å› ç‚ºå®ƒæ˜¯æ–°ç”Ÿæˆçš„ï¼Œä¸åœ¨ rename_map è£¡)
        df_db['transaction_id'] = df['transaction_id']

        # 3. è™•ç†æ—¥æœŸèˆ‡ç©ºå€¼
        date_cols = ['transaction_date', 'posting_date', 'conversion_date']
        for col in date_cols:
            if col in df_db.columns:
                df_db[col] = df_db[col].fillna('').astype(str)

        print(f"âœ… è³‡æ–™æº–å‚™å®Œæˆï¼Œå…± {len(df_db)} ç­†")

        # 4. å¯«å…¥ SQLite
        conn = sqlite3.connect(DB_PATH)
        print(f"ğŸ”Œ é€£æ¥è³‡æ–™åº«: {DB_PATH}")
        
        # ä½¿ç”¨ 'replace' æ¨¡å¼ï¼šæ¯æ¬¡å…¨é‡è¦†è“‹ï¼Œä¿è­‰èˆ‡ ETL çµæœä¸€è‡´
        # å¦‚æœæ‚¨æƒ³è¦ä¿ç•™æ­·å²ç´€éŒ„ï¼Œå¯ä»¥æ”¹ç”¨ 'append' é…åˆ transaction_id å»é‡ï¼Œ
        # ä½†æ—¢ç„¶ etl.py æ˜¯å…¨é‡è·‘ï¼Œé€™è£¡ replace æ˜¯æœ€ä¹¾æ·¨çš„ã€‚
        df_db.to_sql(TABLE_NAME, conn, if_exists='replace', index=False)
        
        # 5. å»ºç«‹ç´¢å¼• (Optimization)
        cursor = conn.cursor()
        print("ğŸ”§ å»ºç«‹ç´¢å¼•ä¸­...")
        # é‡å°å¸¸ç”¨æŸ¥è©¢æ¬„ä½å»ºç´¢å¼•
        cursor.execute(f"CREATE INDEX IF NOT EXISTS idx_txn_date ON {TABLE_NAME} (transaction_date)")
        cursor.execute(f"CREATE INDEX IF NOT EXISTS idx_merchant ON {TABLE_NAME} (merchant_name)")
        cursor.execute(f"CREATE INDEX IF NOT EXISTS idx_card_no ON {TABLE_NAME} (card_no)")
        cursor.execute(f"CREATE INDEX IF NOT EXISTS idx_txn_id ON {TABLE_NAME} (transaction_id)")
        
        conn.commit()
        
        # 6. é©—è­‰
        cursor.execute(f"SELECT count(*) FROM {TABLE_NAME}")
        count = cursor.fetchone()[0]
        print(f"ğŸ“Š é©—è­‰: è³‡æ–™è¡¨ [{TABLE_NAME}] ç›®å‰å…±æœ‰ {count} ç­†è³‡æ–™")
        
        conn.close()
        print("ğŸ‘‹ è³‡æ–™åº«ä½œæ¥­å®Œæˆ")

    except Exception as e:
        print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    load_csv_and_save_to_db()